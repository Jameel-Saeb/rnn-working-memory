# RNN Working Memory Capacity Study

> A computational neuroscience investigation of working memory dynamics in recurrent neural networks

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-orange.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ§  Overview

This project explores how recurrent neural networks model **working memory** - the brain's ability to temporarily hold and manipulate information. Through computational modeling, we investigate memory capacity limits, temporal dynamics, and the neural mechanisms underlying cognitive performance.

**Key Features:**

- ğŸ”¬ Biologically-inspired 1000-neuron RNN with sparse connectivity
- ğŸ§® PyTorch-based temporal decoder for memory analysis
- ğŸ“Š Comprehensive experimental framework with automated testing
- ğŸ“ˆ Publication-quality visualizations and results
- ğŸ”„ Full reproducibility with organized codebase

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/rnn-working-memory.git
cd rnn-working-memory

# Install dependencies
pip install -r requirements.txt

# Run setup and validation
python setup.py

# Quick demonstration
python demo.py

# Run experiments
cd experiments
python experiment1_delay_study.py
```

## ğŸ“Š Key Results

| Metric                   | Finding                                          |
| ------------------------ | ------------------------------------------------ |
| **Memory Decay**         | 95% accuracy (3 steps) â†’ 69% accuracy (20 steps) |
| **Optimal Dynamics**     | Best performance at recurrent gain g â‰ˆ 1.0       |
| **Critical Point**       | Networks operate at "edge of chaos" for memory   |
| **Biological Relevance** | Matches prefrontal cortex dynamics               |

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ src/                    # Core implementation
â”‚   â”œâ”€â”€ rnn_model.py       # 1000-neuron sparse RNN
â”‚   â”œâ”€â”€ decoder.py         # PyTorch temporal decoder
â”‚   â””â”€â”€ utils.py           # Analysis & visualization
â”œâ”€â”€ experiments/           # Research experiments
â”œâ”€â”€ notebooks/            # Interactive exploration
â”œâ”€â”€ results/              # Generated figures & data
â””â”€â”€ tests/               # Comprehensive test suite
```

## ğŸ”¬ Scientific Impact

This work contributes to understanding:

- **Computational principles** of biological working memory
- **Network dynamics** at critical points in neural systems
- **Memory interference** and capacity limitations
- **Applications** to AI systems requiring temporal processing

## ğŸ‘¥ Authors

**Team Members:**

- [Vivian Kang](https://github.com/viviankang)
- [Jameel Saeb](https://github.com/jameelsaeb)
- [Chetanya Singh](https://github.com/chetanyasingh)
- [Ah-Young Moon](https://github.com/ahyoungmoon)

_Developed as part of NEUR680 Computational Neuroscience_

## ğŸ“š Documentation

- ğŸ“– [Complete Documentation](README.md) - Full project details
- âš¡ [Quick Reference](QUICK_REFERENCE.md) - Essential commands
- ğŸ“‹ [Change Log](CHANGELOG.md) - Version history
- ğŸ§ª [Experiments Guide](experiments/) - Research protocols

## ğŸ¯ For Employers

This project demonstrates:

âœ… **Research Skills** - Novel computational neuroscience investigation  
âœ… **Technical Proficiency** - Python, PyTorch, NumPy, scientific computing  
âœ… **Software Engineering** - Clean architecture, testing, documentation  
âœ… **Data Science** - Experimental design, statistical analysis, visualization  
âœ… **Collaboration** - Team-based research project with clear contributions  
âœ… **Communication** - Publication-quality results and presentations

**Technologies:** Python â€¢ PyTorch â€¢ NumPy â€¢ Matplotlib â€¢ Jupyter â€¢ Git

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Citation

If you use this work in your research, please cite:

```bibtex
@misc{kang2024rnn,
  title={RNN Working Memory Capacity Study},
  author={Kang, Vivian and Saeb, Jameel and Singh, Chetanya and Moon, Ah-Young},
  year={2024},
  institution={NEUR680 Computational Neuroscience},
  url={https://github.com/yourusername/rnn-working-memory}
}
```

---

_ğŸ§  Exploring the computational foundations of cognition through neural network modeling_
