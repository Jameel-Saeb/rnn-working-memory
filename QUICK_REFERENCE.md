# RNN Working Memory Project - Quick Reference

## ðŸš€ Quick Start

1. **Setup**: `python setup.py`
2. **Demo**: `python demo.py`
3. **Experiments**: `cd experiments && python experiment1_delay_study.py`

## ðŸ“ Project Structure

```
NEUR680FINAL/
â”œâ”€â”€ ðŸ“„ README.md                    # Main documentation
â”œâ”€â”€ ðŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ðŸ“„ setup.py                     # Setup script
â”œâ”€â”€ ðŸ“„ demo.py                      # Quick demo
â”œâ”€â”€ ðŸ“„ config.ini                   # Configuration
â”œâ”€â”€ ðŸ“„ CHANGELOG.md                 # Version history
â”‚
â”œâ”€â”€ ðŸ“‚ src/                         # Core source code
â”‚   â”œâ”€â”€ __init__.py                 # Package initialization
â”‚   â”œâ”€â”€ rnn_model.py               # RNN implementation
â”‚   â”œâ”€â”€ decoder.py                 # Neural decoder
â”‚   â””â”€â”€ utils.py                   # Utilities & visualization
â”‚
â”œâ”€â”€ ðŸ“‚ experiments/                 # Experiment scripts
â”‚   â”œâ”€â”€ experiment1_delay_study.py # Time delay analysis
â”‚   â””â”€â”€ experiment2_gain_study.py  # Gain parameter study
â”‚
â”œâ”€â”€ ðŸ“‚ notebooks/                   # Jupyter notebooks
â”‚   â””â”€â”€ RNN_working_memory.ipynb   # Original exploration
â”‚
â”œâ”€â”€ ðŸ“‚ results/                     # Results & figures
â”‚   â””â”€â”€ *.png                      # Generated plots
â”‚
â”œâ”€â”€ ðŸ“‚ Final_project_files/         # Presentation assets
â”‚
â””â”€â”€ ðŸ“„ Legacy files                 # Original implementations
    â”œâ”€â”€ Decoder.py                  # (preserved for reproducibility)
    â”œâ”€â”€ Generate_td.py              # (preserved for reproducibility)
    â””â”€â”€ test_input_neuron_counts.py # (preserved for reproducibility)
```

## ðŸ”¬ Core Components

### RNN Model (`src/rnn_model.py`)

- `create_default_model()` - Initialize model parameters
- `initialize_weights()` - Create weight matrices
- `simulate_network()` - Run network simulation
- `generate_training_data()` - Create decoder training data

### Decoder (`src/decoder.py`)

- `WorkingMemoryDecoder` - PyTorch decoder class
- `train_decoder()` - Training pipeline
- `evaluate_multiple_delays()` - Batch evaluation

### Utilities (`src/utils.py`)

- `visualize_network_activity()` - Plot neural dynamics
- `analyze_eigenvalue_spectrum()` - Stability analysis
- `compare_model_parameters()` - Parameter comparison

## ðŸ§ª Running Experiments

```bash
# Time delay study
cd experiments
python experiment1_delay_study.py

# Gain parameter study
python experiment2_gain_study.py
```

## ðŸ“Š Key Results

- **Memory Decay**: Accuracy drops from 93% (5 steps) to 66% (20 steps)
- **Optimal Gain**: g â‰ˆ 1.0 balances stability and dynamics
- **Input Sparsity**: 5-10% connectivity is optimal
- **Encoding**: Subset-based > magnitude-based representation

## ðŸ›  Development

```bash
# Install dependencies
pip install -r requirements.txt

# Run setup validation
python setup.py

# Quick demonstration
python demo.py
```

## ðŸ“š References

1. Barak & Tsodyks (2014) - Working models of working memory
2. Neuromatch Academy - RNN working memory framework
3. Sussillo & Abbott (2009) - Coherent patterns from chaos
