<!DOCTYPE html>
<html lang="en"><head>
<script src="Final_project_files/libs/clipboard/clipboard.min.js"></script>
<script src="Final_project_files/libs/quarto-html/tabby.min.js"></script>
<script src="Final_project_files/libs/quarto-html/popper.min.js"></script>
<script src="Final_project_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Final_project_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Final_project_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Final_project_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="author" content="Vivian Kang, Jameel Saeb, Chetanya Singh, Ah-Young Moon">
  <meta name="dcterms.date" content="2025-05-13">
  <title>Decoding the working memory capacity of recurrent neural network models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Final_project_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Final_project_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="Final_project_files/libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link href="Final_project_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Final_project_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Final_project_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Final_project_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Decoding the working memory capacity of recurrent neural network models</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Vivian Kang, Jameel Saeb, Chetanya Singh, Ah-Young Moon 
</div>
</div>
</div>

  <p class="date">2025-05-13</p>
</section>
<section id="background" class="slide level2">
<h2>Background</h2>
<div style="font-size: 0.6em;">
<p>Working memory serves as the brain’s temporary information workspace, allowing us to hold and manipulate data essential for reasoning, language, and decision-making. Research consistently shows that interconnected neural networks in the prefrontal cortex sustain this vital cognitive function through persistent activity patterns. While biological neurons maintain information through sophisticated mechanisms—including synaptic plasticity, attractor dynamics, and coordinated oscillations—Recurrent Neural Networks (RNNs) provide computational models that capture these temporal dynamics. Through their feedback connections, RNNs can preserve information across time sequences, making them valuable tools for modeling memory processes. Recent theoretical advances by Barak and Tsodyks (2014) have illuminated the critical balance between stability and capacity in neural systems. Their work demonstrates how network parameters—particularly connection strength and sparsity—directly shape a system’s ability to store multiple items without cross-interference. Our project extends this research using Neuromatch Academy’s RNN framework to systematically investigate how key parameters like recurrent gain (g) and temporal delays influence sequential information processing and retention. By analyzing these models’ internal states and decoding capabilities, we aim to clarify the computational boundaries of RNN-based memory systems while drawing meaningful parallels to the neural foundations of human working memory.</p>
<p>Decoder.py contains the code for our decoder and the training loop. Generate_td.py has the code for generating the training data, with the code provided by the project guide for the RNN, and the code for making the training pairs for different delays.</p>
</div>
</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<p>Our project is based on the neuromatch template “The working memory capacity of recurrent neural network models”, and “Working models of working memory” (Barak and Tsodyks 2014).</p>
<p>The project focuses on understanding the different methods that recurrently connected populations in the human brain employ to retain information over time. This corresponds to questions 1 through 5 in the project guide.</p>
</section>
<section id="setup-and-method" class="slide level2">
<h2>Setup and Method</h2>
<div style="font-size: 0.73em;">
<p><strong>RNN:</strong> The Neuromatch project template provided a pretrained recurrent neural network to simulate the recurrently connected populations of neurons in the brain, and their strategies to hold information in working memory.<br>
<br></p>
<p><strong>Data Generation:</strong> The neuromatch project template also provides a function to generate the input sequence or input data for the RNN. It uses Euler’s method to simulate the evolution of model neuron firing rates given the input_layer firing rates. It then generates a sequence of inputs according to different parameters in the model such as how sensitive the weights are or how strongly connected they are, or how interconnected the neurons in the pool are.<br>
<br></p>
<p><strong>Decoder:</strong> For the decoder we implemented a simple neural network. Some of the parameters we chose were a 0.001 learning rate, 64 hidden dimensions. We also utilized the standard adam optimizer, and the cross entropy loss function since we are doing a multi class classification problem. Ie. from the network state it is given, it should predict what Input was activated a few time steps before.</p>
</div>
</section>
<section id="training-data" class="slide level2">
<h2>Training Data</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p>For the training data we wrote code that utilizes the RNN model provided and the make_input function also provided to make training pairs. Our code collects the network state (which of the 1000 neurons are activated) at time t, and which input state was activated at X time steps before time t. It does this for each time step, and a sequence length we choose. It then converts the states and inputs into two numpy arrays.</p>
</div><div class="column" style="width:30%;">
<center>
<video src="IMG_1723.mp4" height="380px" controls="">
</video>
<br> <img src="data.png" height="300px">
</center>
</div></div>
</section>
<section id="steps-taken" class="slide level2">
<h2>Steps taken:</h2>
<div style="font-size: 0.8em;">
<ol type="1">
<li>Write code for a simple neural network which will serve as our decoder</li>
<li>Train our decoder to predict the network state at time t-X, given network state at time t, for five different X values (QUESTION 1)</li>
<li>Test how model performance changes for varying values of sensitivity to synaptic weight changes (g) (QUESTION 2)</li>
<li>Change the magnitude of the input data and see how it affects model performance (QUESTION 3)</li>
<li>Test a stream of inputs as opposed to a single pulse to see model performance (QUESTION 4)</li>
<li>Compare subset based vs.&nbsp;magnitude based encoding strategies for model performance (QUESTION 5)</li>
</ol>
</div>
</section>
<section id="results-of-decoder-for-different-time-delays" class="slide level2">
<h2>Results of Decoder for Different Time Delays</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p>In this first part, we aimed to explore how different delays (i.e., different values of ( X )) affect the decoder’s performance. Below are the test accuracies obtained for various delay values:</p>
<ul>
<li><strong>Delay = 20</strong> → Test Accuracy: <strong>0.6598</strong></li>
<li><strong>Delay = 15</strong> → Test Accuracy: <strong>0.7774</strong></li>
<li><strong>Delay = 10</strong> → Test Accuracy: <strong>0.7694</strong></li>
<li><strong>Delay = 5</strong> → Test Accuracy: <strong>0.9320</strong></li>
</ul>
</div><div class="column" style="width:30%;">
<center>
<video src="IMG_1724.mp4" height="300px" controls="">
</video>
<br> <img src="g_1.png" height="250px">
</center>
</div></div>
</section>
<section id="decoder-performance-across-different-g-values" class="slide level2">
<h2>Decoder Performance across different g-values</h2>
<div style="display: grid; grid-template-columns: 1fr 1fr;">
<div>
<img src="Figures/g_0.5.png" width="100%">
</div>
<div>
<img src="g_1.png" width="100%">
</div>
<div>
<img src="g_1.5.png" width="100%">
</div>
<div>
<img src="g_2.png" width="100%">
</div>
</div>
<div style="font-size: 14px; margin-top: 10px;">
<p><strong>Summary:</strong><br> As <code>g</code> increases, decoder performance at short delays remains high across all values. However, performance at longer delays deteriorates with higher <code>g</code>. This suggests that larger gain values introduce more chaotic or unstable neural dynamics, which degrade the network’s ability to maintain memory over time. Lower <code>g</code> values preserve longer-term memory but may limit representational richness for short delays. Therefore, there is a trade-off between memory stability and dynamic richness controlled by <code>g</code>.</p>
</div>
</section>
<section id="results-of-changing-number-of-neurons-receiving-inputs" class="slide level2">
<h2>Results of Changing Number of Neurons Receiving Inputs</h2>
<div style="font-size: 0.6em;">
<p>To test how the number of neurons receiving input affects working memory performance, we varied the sparsity of the input weight matrix (<code>spIn</code>) while holding the input gain (<code>gIn</code>) constant. We trained decoders across multiple delay values to assess how changing the density of connections from the input layer to the recurrent pool influences memory retention.</p>
<p><strong>Findings:</strong></p>
<ul>
<li>We tested values of <code>spIn = 0.01, 0.05, 0.1, 0.2</code>.</li>
<li>For low <code>spIn</code> (0.01), performance at short delays remained high, but decayed rapidly at longer delays.</li>
<li>As <code>spIn</code> increased to 0.05 and 0.1, performance improved across all delays, suggesting a richer input signal allows for more stable internal representations.</li>
<li>At very high <code>spIn</code> (0.2), performance started to slightly degrade at short delays, potentially due to interference from overlapping inputs.</li>
</ul>
<p><strong>Conclusion:</strong><br>
There exists an optimal input sparsity range (around 0.05–0.1) that balances information injection without overwhelming the network’s internal memory state. Too sparse and the network underperforms; too dense and interference increases.</p>
</div>
</section>
<section id="graphs" class="slide level2">
<h2>Graphs</h2>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 12px;">
<div>
<center>
<img src="Figures/SpIn_values/loss_curves_spIn_0_01.png" width="100%">
<p style="font-size: 0.8em;">
<strong>spIn = 0.01</strong>
</p>
</center>
</div>
<div>
<center>
<img src="Figures/SpIn_values/loss_curves_spIn_0_05.png" width="100%">
<p style="font-size: 0.8em;">
<strong>spIn = 0.05</strong>
</p>
</center>
</div>
<div>
<center>
<img src="Figures/SpIn_values/loss_curves_spIn_0_1.png" width="100%">
<p style="font-size: 0.8em;">
<strong>spIn = 0.1</strong>
</p>
</center>
</div>
<div>
<center>
<img src="Figures/SpIn_values/loss_curves_spIn_0_2.png" width="100%">
<p style="font-size: 0.8em;">
<strong>spIn = 0.2</strong>
</p>
</center>
</div>
</div>
<p>:::</p>
</section>
<section id="results-of-stream-of-inputs" class="slide level2">
<h2>Results of Stream of Inputs</h2>
<div style="font-size: 0.7em;">
<p>Instead of training with a single input pulse followed by a period of rest, we tested the network using a continuous stream of inputs (i.e., no inter-stimulus interval).</p>
<p><strong>Findings:</strong></p>
<ul>
<li>In the streaming case, new inputs consistently degraded the decoder’s ability to recover earlier inputs.</li>
<li>Decoder accuracy dropped more sharply as delay increased, compared to the single-pulse setup.</li>
</ul>
<p><strong>Conclusion:</strong><br>
New inputs overwrite prior activity in the recurrent network, introducing interference. This shows a key limitation in working memory capacity when systems must store past data in the presence of new, ongoing input. It closely mirrors biological working memory decay under distraction.</p>
</div>
</section>
<section id="decoder-performance-and-encoding-strategies" class="slide level2">
<h2>Decoder Performance and Encoding Strategies</h2>
<div style="font-size: 0.7em;">
<p>To determine the most effective way of encoding information into the network, we compared two input representation schemes:</p>
<ol type="1">
<li><strong>Magnitude-Based Encoding</strong>: Input identity is encoded by changing the pulse strength of a fixed neuron subset.</li>
<li><strong>Subset-Based Encoding</strong>: Input identity is encoded by activating distinct neurons (e.g., one-hot encoding), while keeping pulse magnitude fixed.</li>
</ol>
</div>
</section>
<section id="findings" class="slide level2">
<h2>Findings:</h2>
<div style="font-size: 0.6em;">
<ul>
<li>Subset-based encoding consistently produced higher test accuracy across all delays.</li>
<li>Magnitude-based encoding decayed rapidly, especially at longer delays.</li>
</ul>
<p><strong>Conclusion:</strong><br>
Subset-based encoding enables better memory retention because it minimizes overlap and interference between input representations. This suggests that diverse activation patterns are more robust for preserving sequential information over time in recurrent architectures.</p>
<p>:::</p>
<div class="column" style="width:35%;">
<center>
<img src="Figures/Q5_Input_Encoding_Comparison.png" height="300px">
</center>
</div><p>:::</p>
</div>
</section>
<section id="discussion" class="slide level2">
<h2>Discussion</h2>
<div style="font-size: 0.6em;">
<p>Our experiments revealed striking sensitivity in how recurrent neural networks retain information based on the gain parameter (g), which modulates recurrent connection strength. At lower gain values (g = 0.5), network activity quickly dissipated toward zero, severely compromising memory retention. Conversely, higher gain settings (g = 1.5) generated unstable, chaotic activity patterns that overwhelmed input signals and substantially degraded decoding accuracy. The optimal performance emerged at intermediate gain values (g ≈ 1.0), where networks achieved a critical balance between stability and adaptability. This equilibrium enabled sustained information preservation across extended delays without introducing significant noise or uncontrolled activity. These findings validate theoretical models suggesting that networks operating at the “edge of chaos” maximize memory capacity by harmonizing persistence with flexibility.</p>
<p>Our decoding analyses further demonstrated that memory performance gradually diminished as temporal delays between inputs and decoding increased. This pattern suggests that even in optimally calibrated networks, memory traces naturally degrade over time—paralleling the biological limitations observed in neural systems. These results illuminate fundamental trade-offs inherent to recurrent architectures: enhancing stability improves memory persistence but risks excessive smoothing of network dynamics, while increasing gain heightens sensitivity but potentially triggers instability. Precisely calibrating these parameters proves essential not only for accurate modeling of biological cognition but also for advancing artificial systems dependent on sequential memory, including language models and time-series prediction frameworks.</p>
</div>
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<div style="font-size: 0.6em;">
<p>Our project demonstrates that recurrent neural networks serve as powerful computational frameworks for investigating working memory dynamics. Through systematic manipulation of network gain parameters and rigorous analysis of sequential information retention and decoding capabilities, we’ve illuminated fundamental trade-offs between stability and capacity in memory systems. Our findings reveal that optimal memory performance emerges precisely when networks operate within intermediate gain ranges, establishing a critical balance between information persistence and environmental responsiveness. This equilibrium closely parallels biological neural systems, which must maintain information sufficiently for task completion while preventing disruptive runaway activity patterns. These results simultaneously validate theoretical neuroscience predictions and provide practical design insights for artificial memory architectures in machine learning applications. However, as with any computational model, important questions remain regarding biological fidelity and the broader applicability of these findings across diverse contexts—questions that motivate our proposed future research directions.</p>
</div>
</section>
<section id="future-directions" class="slide level2">
<h2>FUTURE DIRECTIONS</h2>
<div style="font-size: 0.5em;">
<p>Our findings establish a foundation for several promising research paths that could enhance our understanding of working memory mechanisms in recurrent neural networks:</p>
<p><strong>Explore Expanded Parameter Spaces</strong> - Future work should systematically investigate additional network characteristics including sparsity patterns, input noise distributions, and varied time constants to examine their interactions with gain and delay. This comprehensive approach may reveal subtle dynamics governing memory stability and retention capabilities.</p>
<p><strong>Investigate Advanced Encoding Strategies</strong> - While our current implementation relies on one-hot encoding for input representation, exploring sophisticated alternatives like population coding or distributed representations could significantly enhance memory capacity and noise resilience.</p>
<p><strong>Integrate Neurobiologically Inspired Mechanisms</strong> - Incorporating elements such as synaptic plasticity rules, targeted inhibitory control circuits, and coordinated oscillatory patterns would increase biological realism and provide deeper insights into how neural systems maintain stable memory representations.</p>
<p><strong>Validate Through Real-World Sequential Processing</strong> - Extending our modeling framework beyond abstract sequences to practical applications in language processing, sensory prediction, or motor planning could demonstrate the translational value of these findings for artificial intelligence systems.</p>
<p><strong>Evaluate Long-Term Stability and Scaling Properties</strong> - Conducting simulations with expanded network architectures and extended sequence lengths will help determine whether our observed principles remain consistent across more complex scenarios and realistic computational demands.</p>
<p>By pursuing these research directions, we can continue bridging critical gaps between theoretical models, biological mechanisms, and practical applications in both computational neuroscience and machine learning domains.</p>
</div>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Final_project_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Final_project_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Final_project_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Final_project_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Final_project_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Final_project_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Final_project_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Final_project_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Final_project_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Final_project_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>